import json
import logging
from collections import Counter
from datetime import datetime, timedelta

import numpy as np

from app_init import db
from models import CommunicationProfile, User, UserInteraction, UserPreference

# Setup logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("learning_analytics")


class LearningAnalytics:
    """Analytics engine that tracks and analyzes user progress over time.

    Used for the caregiver dashboard to visualize improvement.
    """

    def __init__(self, user_id=None):
        self.user_id = user_id
        logger.info(f"Initializing LearningAnalytics for user {user_id}")

    def get_interaction_frequency(self, period="week"):
        """Get interaction frequency over time.

        Args:
            period (str): 'week', 'month', or 'year'

        Returns:
            dict: Labels and data for charting
        """
        if not self.user_id:
            return {"labels": [], "data": []}

        # Define time period
        if period == "week":
            start_date = datetime.now() - timedelta(days=7)
            date_format = "%A"  # Day name
            groupby_format = "%w"  # Day of week (0-6)
        elif period == "month":
            start_date = datetime.now() - timedelta(days=30)
            date_format = "Week %U"  # Week number
            groupby_format = "%U"  # Week of year
        elif period == "year":
            start_date = datetime.now() - timedelta(days=365)
            date_format = "%b"  # Month abbreviation
            groupby_format = "%m"  # Month (01-12)
        else:
            return {"labels": [], "data": []}

        # Get interactions for the user
        interactions = UserInteraction.query.filter(
            UserInteraction.user_id == self.user_id,
            UserInteraction.timestamp >= start_date,
        ).all()

        # Count interactions by date
        interaction_counts = {}

        for interaction in interactions:
            date_key = interaction.timestamp.strftime(groupby_format)
            if date_key in interaction_counts:
                interaction_counts[date_key] += 1
            else:
                interaction_counts[date_key] = 1

        # Format for charts
        if period == "week":
            days = [
                "Sunday",
                "Monday",
                "Tuesday",
                "Wednesday",
                "Thursday",
                "Friday",
                "Saturday",
            ]
            labels = days
            data = [interaction_counts.get(str(i), 0) for i in range(7)]
        elif period == "month":
            # Last 4 weeks
            week_numbers = [
                (datetime.now() - timedelta(days=7 * i)).strftime(groupby_format)
                for i in range(4)
            ]
            labels = [f"Week {w}" for w in week_numbers]
            data = [interaction_counts.get(w, 0) for w in week_numbers]
        elif period == "year":
            # Last 12 months
            month_names = [
                "Jan",
                "Feb",
                "Mar",
                "Apr",
                "May",
                "Jun",
                "Jul",
                "Aug",
                "Sep",
                "Oct",
                "Nov",
                "Dec",
            ]
            current_month = datetime.now().month
            labels = [month_names[((current_month - i - 1) % 12)] for i in range(12)]
            labels.reverse()

            months = [
                str(((current_month - i - 1) % 12) + 1).zfill(2) for i in range(12)
            ]
            months.reverse()
            data = [interaction_counts.get(m, 0) for m in months]

        return {"labels": labels, "data": data}

    def get_interaction_methods(self):
        """Get distribution of interaction methods.

        Returns:
            dict: Labels and data for charting
        """
        if not self.user_id:
            return {"labels": [], "data": []}

        # Get all interactions for the user
        interactions = UserInteraction.query.filter_by(user_id=self.user_id).all()

        # Count by interaction type
        method_counts = {"text": 0, "gesture": 0, "symbol": 0, "eye": 0, "sound": 0}

        for interaction in interactions:
            if not interaction.text:
                continue

            if interaction.text.startswith("symbol:"):
                method_counts["symbol"] += 1
            elif interaction.text.startswith("gesture:"):
                method_counts["gesture"] += 1
            elif interaction.text.startswith("eye:"):
                method_counts["eye"] += 1
            elif interaction.text.startswith("sound:"):
                method_counts["sound"] += 1
            else:
                method_counts["text"] += 1

        # Ensure we have some data for visualization purposes
        # Production systems would remove this
        total = sum(method_counts.values())
        if total == 0:
            # Generate some initial data for demonstration
            method_counts["text"] = 7
            method_counts["gesture"] = 5
            method_counts["symbol"] = 4
            method_counts["eye"] = 2
            method_counts["sound"] = 1

        return {
            "labels": list(method_counts.keys()),
            "data": list(method_counts.values()),
        }

    def get_learning_progress(self):
        """Calculate learning progress metrics.

        Returns:
            dict: Progress metrics
        """
        if not self.user_id:
            return {
                "vocabulary_growth": 0,
                "vocabulary_percentage": 0,
                "expression_growth": 0,
                "expression_percentage": 0,
                "multimodal_growth": 0,
                "multimodal_percentage": 0,
            }

        # Get all interactions
        all_interactions = UserInteraction.query.filter_by(user_id=self.user_id).all()

        # Calculate metrics
        # 1. Vocabulary growth
        vocabulary = set()
        recent_vocabulary = set()

        # 2. Expression clarity (confidence scores)
        confidence_scores = []
        recent_confidence_scores = []

        # 3. Multimodal usage
        interaction_types = []
        recent_interaction_types = []

        # Cutoff date for recent data (last 2 weeks)
        recent_cutoff = datetime.now() - timedelta(days=14)

        for interaction in all_interactions:
            if not interaction.text:
                continue

            # Get base content without prefix
            content = interaction.text
            if ":" in content:
                parts = content.split(":", 1)
                if len(parts) > 1:
                    content = parts[1].strip()

            # Add to vocabulary sets
            if content:
                vocabulary.add(content.lower())
                if interaction.timestamp >= recent_cutoff:
                    recent_vocabulary.add(content.lower())

            # Add to confidence scores
            if interaction.confidence:
                confidence_scores.append(interaction.confidence)
                if interaction.timestamp >= recent_cutoff:
                    recent_confidence_scores.append(interaction.confidence)

            # Add to interaction types
            interaction_type = "text"
            if interaction.text.startswith("symbol:"):
                interaction_type = "symbol"
            elif interaction.text.startswith("gesture:"):
                interaction_type = "gesture"
            elif interaction.text.startswith("eye:"):
                interaction_type = "eye"
            elif interaction.text.startswith("sound:"):
                interaction_type = "sound"

            interaction_types.append(interaction_type)
            if interaction.timestamp >= recent_cutoff:
                recent_interaction_types.append(interaction_type)

        # For a real application, these would be calculated from long-term historical data
        # For demonstration, we'll use placeholder calculations

        # 1. Vocabulary growth (% increase in unique expressions)
        vocabulary_count = len(vocabulary)
        recent_vocabulary_count = len(recent_vocabulary)
        vocabulary_growth = 15  # Sample growth %
        vocabulary_percentage = min(100, max(0, vocabulary_count * 5))  # Scale for demo

        if vocabulary_count > 0:
            # Calculate actual growth if we have enough data
            old_vocabulary_count = vocabulary_count - recent_vocabulary_count
            if old_vocabulary_count > 0:
                vocabulary_growth = int(
                    (recent_vocabulary_count / old_vocabulary_count - 1) * 100
                )

        # 2. Expression clarity (confidence improvement)
        avg_confidence = np.mean(confidence_scores) if confidence_scores else 0.5
        recent_avg_confidence = (
            np.mean(recent_confidence_scores) if recent_confidence_scores else 0.5
        )
        expression_growth = 8  # Sample growth %
        expression_percentage = min(100, max(0, int(avg_confidence * 100)))

        if avg_confidence > 0:
            # Calculate actual growth if we have enough data
            old_avg_confidence = avg_confidence
            if old_avg_confidence > 0:
                expression_growth = int(
                    (recent_avg_confidence / old_avg_confidence - 1) * 100
                )

        # 3. Multimodal usage (variety of input methods)
        unique_types = len(set(interaction_types))
        recent_unique_types = len(set(recent_interaction_types))
        multimodal_growth = 23  # Sample growth %
        multimodal_percentage = min(100, max(0, unique_types * 20))  # Scale for demo

        # If we have real data, calculate growth
        if len(interaction_types) > len(recent_interaction_types) and unique_types > 0:
            old_unique_types = unique_types - recent_unique_types
            if old_unique_types > 0:
                multimodal_growth = int(
                    (recent_unique_types / old_unique_types - 1) * 100
                )

        return {
            "vocabulary_growth": vocabulary_growth,
            "vocabulary_percentage": vocabulary_percentage,
            "expression_growth": expression_growth,
            "expression_percentage": expression_percentage,
            "multimodal_growth": multimodal_growth,
            "multimodal_percentage": multimodal_percentage,
        }

    def get_frequent_expressions(self, limit=10):
        """Get most frequently used expressions.

        Args:
            limit (int): Maximum number of expressions to return

        Returns:
            list: Frequent expressions with counts
        """
        if not self.user_id:
            return []

        # Get all interactions
        interactions = UserInteraction.query.filter_by(user_id=self.user_id).all()

        # Extract expressions
        expressions = []
        for interaction in interactions:
            if not interaction.text:
                continue

            # Get base content without prefix
            content = interaction.text
            if ":" in content:
                parts = content.split(":", 1)
                if len(parts) > 1:
                    content = parts[1].strip()

            if content:
                expressions.append(content)

        # Count frequencies
        counter = Counter(expressions)

        # Convert to list and sort
        frequent_expressions = [
            {"text": text, "count": count} for text, count in counter.most_common(limit)
        ]

        return frequent_expressions

    def generate_system_suggestions(self):
        """Generate AI system suggestions based on user behavior patterns.

        Returns:
            list: System suggestions
        """
        if not self.user_id:
            return []

        # Get communication profile
        from models import CommunicationProfile

        profile = CommunicationProfile.get_latest_profile(self.user_id)

        # Get interactions
        interactions = UserInteraction.query.filter_by(user_id=self.user_id).all()

        # Analyze patterns
        interaction_types = []
        intent_counts = {}
        expression_counts = {}

        for interaction in interactions:
            # Track input modality
            interaction_type = "text"
            if interaction.text:
                if interaction.text.startswith("symbol:"):
                    interaction_type = "symbol"
                elif interaction.text.startswith("gesture:"):
                    interaction_type = "gesture"
                elif interaction.text.startswith("eye:"):
                    interaction_type = "eye"
                elif interaction.text.startswith("sound:"):
                    interaction_type = "sound"

            interaction_types.append(interaction_type)

            # Track intent usage
            if interaction.intent:
                if interaction.intent in intent_counts:
                    intent_counts[interaction.intent] += 1
                else:
                    intent_counts[interaction.intent] = 1

        # Generate suggestions
        suggestions = []

        # Communication mode suggestions
        modality_counter = Counter(interaction_types)
        primary_mode = (
            modality_counter.most_common(1)[0][0] if modality_counter else "text"
        )

        # If profile doesn't match primary mode, suggest update
        if profile and profile.primary_mode != primary_mode:
            suggestions.append(
                {
                    "title": f"Update Communication Profile",
                    "description": f"User primarily communicates using {primary_mode} mode. Consider updating their primary communication mode setting.",
                    "suggestion_type": "profile",
                    "confidence": 0.85,
                }
            )

        # Suggest adding symbols for frequent intents
        if intent_counts and "symbol" not in modality_counter:
            top_intent = max(intent_counts.items(), key=lambda x: x[1])[0]
            suggestions.append(
                {
                    "title": "Try Symbol-Based Communication",
                    "description": f'User frequently expresses "{top_intent}" intent. Consider introducing symbols for this intent to potentially enhance communication.',
                    "suggestion_type": "communication",
                    "confidence": 0.75,
                }
            )

        # Suggest emotional context settings
        if any(
            intent in intent_counts
            for intent in ["express_joy", "express_sadness", "express_anger"]
        ):
            suggestions.append(
                {
                    "title": "Enable Emotional Context",
                    "description": "User expresses emotional content. Ensure emotional context processing is enabled for more natural communication.",
                    "suggestion_type": "setting",
                    "confidence": 0.8,
                }
            )

        # Add more suggestions based on other patterns
        # (limited to a few examples for this implementation)

        return suggestions

    @classmethod
    def generate_mock_interaction(
        cls, user_id, text=None, intent=None, confidence=None
    ):
        """Generate a mock interaction for demonstration purposes.

        Args:
            user_id (int): User ID
            text (str, optional): Interaction text
            intent (str, optional): Intent
            confidence (float, optional): Confidence score

        Returns:
            UserInteraction: Created interaction
        """
        from models import UserInteraction

        # Default values
        if text is None:
            # Generate a simple interaction
            options = [
                "I want water",
                "Help me please",
                "I'm feeling happy",
                "I don't like that",
                "symbol:food",
                "symbol:drink",
                "gesture:nod",
                "gesture:shake",
            ]
            text = np.random.choice(options)

        if intent is None:
            if text.startswith("symbol:"):
                intent = "communicate_symbol"
            elif text.startswith("gesture:"):
                intent = "communicate_gesture"
            else:
                options = ["request", "inform", "express", "acknowledge", "question"]
                intent = np.random.choice(options)

        if confidence is None:
            confidence = np.random.uniform(0.6, 0.95)

        # Create and save interaction
        interaction = UserInteraction(
            user_id=user_id,
            text=text,
            intent=intent,
            confidence=confidence,
            timestamp=datetime.now()
            - timedelta(days=np.random.randint(0, 30), hours=np.random.randint(0, 24)),
        )

        db.session.add(interaction)
        db.session.commit()

        return interaction

    @classmethod
    def generate_demo_data(cls, user_id, count=50):
        """Generate demo data for a new user.

        Args:
            user_id (int): User ID
            count (int): Number of interactions to generate

        Returns:
            list: Generated interactions
        """
        interactions = []

        # Sample data patterns
        modalities = ["text", "symbol", "gesture", "eye", "sound"]
        modality_weights = [0.4, 0.3, 0.2, 0.05, 0.05]

        symbols = [
            "food",
            "drink",
            "bathroom",
            "happy",
            "sad",
            "tired",
            "help",
            "yes",
            "no",
        ]
        gestures = [
            "nod",
            "shake",
            "point_up",
            "wave",
            "thumbs_up",
            "thumbs_down",
            "open_palm",
        ]

        text_phrases = [
            "I want water",
            "Help me please",
            "I'm feeling happy",
            "I don't like that",
            "I need help",
            "I'm hungry",
            "I'm thirsty",
            "I'm tired",
            "Thank you",
            "Stop please",
        ]

        for i in range(count):
            # Choose modality
            modality = np.random.choice(modalities, p=modality_weights)

            # Generate text based on modality
            if modality == "text":
                text = np.random.choice(text_phrases)
                intent = "communicate"
            elif modality == "symbol":
                symbol = np.random.choice(symbols)
                text = f"symbol:{symbol}"
                intent = f"symbol_{symbol}"
            elif modality == "gesture":
                gesture = np.random.choice(gestures)
                text = f"gesture:{gesture}"
                intent = f"gesture_{gesture}"
            elif modality == "eye":
                regions = [
                    "top_left",
                    "top_right",
                    "bottom_left",
                    "bottom_right",
                    "center",
                ]
                region = np.random.choice(regions)
                text = f"eye:{region}"
                intent = f"eye_tracking"
            else:  # sound
                sounds = ["hum", "click", "soft", "loud", "distress"]
                sound = np.random.choice(sounds)
                text = f"sound:{sound}"
                intent = f"vocalization"

            # Generate confidence (with slight improvement trend over time)
            days_ago = count - i
            base_confidence = (
                0.6 + (i / count) * 0.3
            )  # Ranges from 0.6 to 0.9 over time
            confidence = min(
                0.98, max(0.5, base_confidence + np.random.uniform(-0.1, 0.1))
            )

            # Create timestamp (more recent interactions are newer)
            timestamp = datetime.now() - timedelta(
                days=days_ago,
                hours=np.random.randint(0, 24),
                minutes=np.random.randint(0, 60),
            )

            # Create interaction
            interaction = UserInteraction(
                user_id=user_id,
                text=text,
                intent=intent,
                confidence=confidence,
                timestamp=timestamp,
            )

            db.session.add(interaction)
            interactions.append(interaction)

        # Create communication profile
        profile = CommunicationProfile(
            user_id=user_id, primary_mode="text", secondary_mode="symbol"
        )

        db.session.add(profile)

        # Create preferences
        preferences = [
            UserPreference(
                user_id=user_id,
                type="gesture_sensitivity",
                value="0.8",
                source="system",
            ),
            UserPreference(
                user_id=user_id, type="response_speed", value="1.0", source="manual"
            ),
            UserPreference(
                user_id=user_id, type="sound_sensitivity", value="0.7", source="system"
            ),
            UserPreference(
                user_id=user_id, type="emotion_display", value="true", source="manual"
            ),
        ]

        for pref in preferences:
            db.session.add(pref)

        db.session.commit()

        return interactions

# ==============================================================================
# © 2025 Everett Nathaniel Christman & Misty Gail Christman
# The Christman AI Project — Luma Cognify AI
# All rights reserved. Unauthorized use, replication, or derivative training 
# of this material is prohibited.
# Core Directive: "How can I help you love yourself more?" 
# Autonomy & Alignment Protocol v3.0
# ==============================================================================
